# EAS503 - Phone Price Prediction

Here’s a comprehensive summary of the work done in this project:

---

## **Summary**

### **1. Database and Data Preprocessing**
- **Database Connection**:
  - Connected to the normalized **3NF** database `mobile_phones.db` using SQLite.
  - Retrieved data using SQL `JOIN` queries across multiple tables (`phones`, `screen_specs`, `camera_specs`, `phone_features`, and `storage_specs`) into a Pandas DataFrame.

- **Data Exploration**:
  - Analyzed distributions, capped values, and correlations using `yprofile` and correlation matrices.
  - Identified the need to stratify data by `price_range` for train/test splitting.

- **Feature Engineering**:
  - Created derived features:
    - `total_camera` = `front_camera` + `primary_camera`
    - `total_pixels` = `px_height` * `px_width`
  - Imputed missing/zero values (e.g., `sc_w`) using the mean.
  - Dropped redundant or low-importance features: `front_camera`, `primary_camera`, `px_height`, `px_width`, `three_g`.

- **Normalization**:
  - Applied transformations:
    - `StandardScaler` for standardization.
    - `MinMaxScaler` and `LogTransformation` for select features.
  - Used `OneHotEncoder` for categorical features.

---

### **2. Experiments and Model Training**
**Experiment #1**:
- Built a preprocessing pipeline with:
  - `StandardScaler`, `MinMaxScaler`, `LogTransformation`, `OneHotEncoding`.
  - Trained a **Logistic Regression** model.
  - Logged metrics (e.g., F1-score, TP, TN, FP, FN) in MLFlow on DagsHub.
  - Used 10-fold cross-validation and hyperparameter tuning to optimize results.

**Experiment #2**:
- Extended preprocessing to train:
  - `LogisticRegression`, `RidgeClassifier`, `RandomForestClassifier`, and `XGBClassifier`.
  - Logged results (accuracy, F1-score, precision) in MLFlow.
  - Selected `RandomForestClassifier` as the best model based on performance and overfitting checks.

**Experiment #3**:
- Performed feature engineering and logged the results:
  - Tested combinations like `performance = battery_power * ram`.
  - Observed significant performance gains with the `total_pixels` and `total_camera` features.

**Experiment #4**:
- Conducted feature selection using:
  - **Correlation Threshold**: Removed highly correlated features.
  - **Feature Importance**: Used model-based feature importance scores.
  - **Variance Threshold**: Eliminated low-variance features.

**Experiment #5**:
- Applied PCA for dimensionality reduction:
  - Created a scree plot to determine optimal components.
  - Reduced features to 5 principal components for further experiments.

**Experiment #6**:
- Custom Experiment:
  - Tested ensemble methods combining Logistic Regression, Random Forest, and PCA-based classifiers.
  - Evaluated models on unseen test data and logged metrics in MLFlow.

**Experiment #7**:
- Designed a hybrid pipeline with Random Forest and PCA.
  - This experiment produced the best results (F1-score: 0.91, Accuracy: 0.91).
  - Declared as the final model after cross-validation and overfitting checks.

---

### **3. Model Finalization**
- **Model Selection**:
  - Selected the pipeline from Experiment #7 (Random Forest with PCA) as the final model.
  - Addressed overfitting with hyperparameter tuning and cross-validation.

- **Model Saving**:
  - Saved the model pipeline (`preprocessing`, `PCA`, `RandomForest`) using `joblib`:
    - File: `random_forest_pca_full_pipeline.joblib`.

---

### **4. Backend Development**
- **FastAPI Backend**:
  - Developed a FastAPI application with:
    - `/`: Root endpoint for a welcome message.
    - `/predict/`: Accepts user inputs as JSON and returns predictions.
  - Integrated Pydantic for schema validation (`PhoneData` model).

- **Testing**:
  - Validated predictions using `test_samples.json`.
  - Handled edge cases and invalid input gracefully.

---

### **5. Frontend Development**
- **Streamlit Application**:
  - Built an interactive app:
    - Sliders for user input across all features.
    - Dynamically computed derived features (`total_camera`, `total_pixels`).
    - Integrated with the FastAPI backend for real-time predictions.

- **UI Features**:
  - Clean and intuitive design.
  - Displayed predictions and allowed results to be downloaded as a CSV.

---

### **6. Containerization**
- **Dockerized the FastAPI Application**:
  - Created a `Dockerfile` to package the backend, dependencies, and model.
  - Configured the container to:
    - Install dependencies from `requirements.txt`.
    - Run the FastAPI app using `uvicorn` on port `80`.

- **Docker Hub Deployment**:
  - Built and pushed the containerized application to Docker Hub.
  - Enabled portability and cloud deployment.

---

### **7. Integration and Deployment**
- Deployed the containerized FastAPI app to a cloud platform (AWS/GCP/Azure).
- Verified the deployment and tested the API with sample requests.

---

### **8. Results and Visualization**
- **Model Comparison**:
  - Plotted F1-scores, precision, recall, and accuracy across all experiments.
  - Declared Experiment #7 (Random Forest + PCA) as the best model.

- **Prediction Output**:
  - Validated model predictions using test cases (`test_samples.json`).

---

### **9. Deliverables**
1. **Code and Artifacts**:
   - Final model: `random_forest_pca_full_pipeline.joblib`.
   - FastAPI app: `fas_app.py`.
   - Streamlit app: `streamlit_app.py`.
   - Docker container.

2. **Project Documentation**:
   - Created a JupyterBook site:
     - Resume.
     - Embedded video walkthrough (12–15 minutes).
     - Links to MLFlow experiments, Docker Hub image, deployed model, and Streamlit app.

3. **Video Presentation**:
   - Recorded a detailed explanation of the project.
   - Walkthrough of the Jupyter Notebook and key deliverables.

---

### **Achievements**
- Built an end-to-end system for predicting mobile phone price ranges.
- Integrated backend, frontend, and deployment for a seamless user experience.
- Achieved high model performance (F1-score: 0.91, Accuracy: 0.91) with robust validation.

---